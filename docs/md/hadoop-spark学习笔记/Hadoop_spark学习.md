引擎（神经网络）

燃料（大数据）
Hadoop生态圈
Spark生态圈

### 1.主要功能

	分布式文件系统HDFS
	分布式资源调度YARN
	分布式计算框架MapReduce
	Hadoop分布式集群搭建
### 2.涉及的技术

	前沿技术 spark flink beam
	1.数据采集
	2.数据存储
	3.数据处理/分析/挖掘
	4.可视化
## 3.大数据概述

	大数据定义
		大数据4v特征
![TIM截图20181211174228](C:\Users\wyx\Desktop\新建文件夹\TIM截图20181211174228.png)

![TIM截图20181211174228](C:\Users\wyx\Desktop\新建文件夹\TIM图片20181211174528.png)



### 4.大数据背景

```
大数据在技术架构上带来的挑战
	1.对现有数据库管理技术的挑战
	2.经典数据库技术并没有考虑数据的多类别
	3.实时性的技术挑战
	4.网络架构、数据运维的挑战
	5.数据隐私
	6.数据源的复杂多样
```

### 5.如何对大数据进行存储和分析？

```
系统瓶颈
	存储容量
	读写速度
	计算效率
Google 大数据技术（没有开源）
	MapReduce
	BigTable
	GFS
```

#### 6.Hadoop概述

```
可靠，可扩展，分布式的
HDFS数据存储
yarn作业调度，资源管理
MapReduce基于yarn的并行处理框架

开源的，分布式存储+分布式计算平台

优势：
	可靠性：
          数据存储：数据块多副本
          数据计算：重新调度作业计算
     高扩展性：
     	存储/计算资源不够时，可以横向的线性扩展机器
     	一个进群中可以包含数以千计的节点
     其他：
     	存储在廉价机器上，降低成本
     	成熟的生态圈
	
```



![TIM截图20181211202824](C:\Users\wyx\Desktop\新建文件夹\TIM截图20181211202824.png)

#### Hadoop核心组件之分布式文件系统HDFS

```源自Google的GFS论文，论文发表于2003年10月。
HDFS是GFS的克隆版
HDFS特点：扩展性&容错性&海量数量存储
将文件切分成制定大小的数据块并以多副本的存储在多个机器上
数据切分、多副本、容错等操作对用户是透明的

```

下图中，part-0 副本数2 block1，3，block编号是为了按顺序组成文件，每个block存在多个副本。数据切分，多副本，容错率高。

![TIM截图20181211203728](C:\Users\wyx\Desktop\新建文件夹\TIM截图20181211203728.png)

#### Hadoop核心组件之资源调度系统YARN

```
YARN:Yet Another Resource Negotiator
负责整个集群资源的管理和调度
特点：扩展性&容错性&多框架资源统一调度 （提高计算能力/可以重新启动错误程序/可以跑多种不同框架的）
```

#### Hadoop核心组件之分布式计算框架MapReduce

```
源自于Google的MapReduce论文，论文发表于2004年12月
MapReduce是Google MapReduce的克隆版
特点：扩展性&容错性&海量数据处理啊
```

例子word cont 给你一篇文章统计数字

![TIM截图20181211205126](C:\Users\wyx\Desktop\新建文件夹\TIM截图20181211205126.png)

#### Hadoop版本用cdh版本。

# HDFS的设计目标

1. 非常巨大的分布式文件系统
2. 运行在普通廉价的硬件上
3. 易扩展、为用户提供性能不错的文件储存服务

 

### HDFS优点

1.数据冗余、硬件容错

2.适合存储大文件

3.处理流式的数据访问

4.可构建在廉价的机器上

### HDFS缺点

1.低延迟的数据访问（大文件很难做到秒级别的读取）

2.小文件的存储（对应的元数据存储在上面对namenode压力大）

## YARN执行流程



![img](https://upload-images.jianshu.io/upload_images/9524278-fac05e032ef7bf8a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/890/format/webp)