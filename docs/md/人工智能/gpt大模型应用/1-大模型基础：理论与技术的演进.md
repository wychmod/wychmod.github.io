# 初探大模型：起源与发展
## 预热篇：解码注意力机制（Attention）

深度学习中的注意力机制是一种模拟人类注意力聚焦方式的技术，它允许模型在处理信息时，优先考虑对当前任务更为重要的部分。这种机制特别适用于处理序列数据，如文本、语音或时间序列数据。

### 注意力机制的基本概念

1. **背景**：在深度学习模型，特别是循环神经网络（RNN）和长短期记忆网络（LSTM）中，模型必须处理序列数据。传统的RNN在处理长序列时，会遇到信息丢失或梯度消失/爆炸的问题。

2. **引入注意力机制**：为了解决这些问题，注意力机制被提出。它通过为序列中的不同部分分配不同的权重，帮助模型更有效地聚焦于关键信息，同时忽略不太相关的部分。

### 注意力机制的工作原理

1. **权重分配**：模型会为输入数据中的每个部分计算一个权重（或重要性评分），这些权重决定了在生成输出时各部分的影响程度。

2. **上下文向量**：利用这些权重，模型生成一个“上下文向量”，这个向量是加权后的输入数据的总和，代表当前步骤所需关注的信息。

### 编码器-解码器架构

在带有注意力机制的神经网络中，常见的一种架构是编码器-解码器（Encoder-Decoder）架构，这在机器翻译、文本摘要等任务中非常普遍。

1. **编码器（Encoder）**：
   - **作用**：编码器的作用是处理输入数据（如一段文本），并将其转换成一系列的内部状态或表示，这些表示捕获了输入数据的关键信息。
   - **输出**：编码器的输出通常是一系列向量，每个向量对应输入数据的一个元素（如一个单词）。

2. **解码器（Decoder）**：
   - **作用**：解码器负责生成输出（如翻译后的文本）。它根据编码器的输出以及到目前为止已生成的输出（例如前一个单词）来决定下一个输出元素。
   - **注意力在此的作用**：解码器可以利用注意力机制来决定在生成每个新元素时，应该更加关注编码器输出中的哪一部分。

### 注意力机制的优势

1. **改进长距离依赖处理**：注意力机制使模型能够处理长序列中的长距离依赖问题，这在传统的RNN中是一个挑战。

2. **提高模型灵活性**：模型可以学习在处理不同类型的任务时聚焦于序列的哪些部分。

3. **解释性强**：通过分析注意力权重，我们可以获得模型决策过程的更好理解。它们被广泛用于提高神经网络的可解释性，帮助解释模型的决策过程，使得原本被认为是黑盒模型的神经网络变得更易解释。这对于人们对机器学习模型的公平性、可追溯性和透明度的关注具有重要意义。

![](../../youdaonote-images/Pasted%20image%2020231216164826.png)

![](../../youdaonote-images/Pasted%20image%2020231216164837.png)

## 变革里程碑：Transformer的崛起

Transformer 是一种基于注意力机制的深度学习模型架构，它在自然语言处理（NLP）和其他序列处理任务中取得了显著的成果。Transformer 的提出标志着从以往依赖循环神经网络（RNN）和长短期记忆网络（LSTM）的时代转向更加高效和有效的注意力机制。

### Transformer 基本架构

Transformer 模型由两大部分组成：编码器（Encoder）和解码器（Decoder），每部分都包含多个相同的层。

1. **编码器**：包含多个编码器层，每层有两个子层。第一个是多头注意力机制（Multi-Head Attention），第二个是简单的、位置全连接的前馈网络。

2. **解码器**：包含多个解码器层，每层也有两个主要子层。第一个是多头注意力机制，第二个是前馈网络。解码器还包含一个额外的多头注意力层，用于关注编码器的输出。

### Transformer 与传统注意力机制的改进

1. **多头注意力（Multi-Head Attention）**：
   - **改进点**：Transformer 通过多头注意力机制并行地处理数据，每个“头”关注输入的不同部分。这使得模型能够同时捕获数据的多种特征，增强了模型的表示能力。
   - **相对优势**：相比于传统单一注意力机制，多头注意力提供了更丰富和更复杂的输入表示。

2. **去除循环和卷积**：
   - **改进点**：与依赖循环结构的RNN和LSTM不同，Transformer 完全依赖于注意力机制，去除了循环和卷积，这使得数据处理可以并行化，极大提高了训练效率。
   - **相对优势**：并行化处理显著减少了训练时间，同时也解决了长距离依赖问题。

3. **位置编码（Positional Encoding）**：
   - **改进点**：由于Transformer不使用循环结构，因此需要另一种方法来理解序列中的顺序信息。Transformer 通过向输入添加位置编码来实现这一点。
   - **相对优势**：位置编码使模型能够考虑单词的顺序，对于语言处理等序列任务至关重要。

4. **可扩展性**：
   - **改进点**：Transformer 的结构使其非常适合大规模训练和处理大量数据。
   - **相对优势**：相对于RNN和LSTM，Transformer 更容易扩展和优化，特别是在处理大型数据集时。

5. **提高了处理长序列数据的能力**：
   - **改进点**：由于并行化和有效的注意力机制，Transformer 能更好地处理长序列数据。
   - **相对优势**：在处理长距离依赖和复杂序列结构方面，Transformer 显著优于传统的基于循环的网络。

### 应用和影响

Transformer 自推出以来，在自然语言处理领域产生了深远的影响。它是许多先进模型（如BERT、GPT系列）的基础，并被广泛应用于机器翻译、文本生成、摘要、问答系统等多种任务。

总体而言，Transformer 通过其独特的多头注意力机制和去除循环依赖的设计，显著提高了模型处理复杂序列任务的效率和准确性。

Transformer 和 Self-Attention 是深度学习中的重要概念，它们在处理序列数据，特别是在自然语言处理（NLP）任务中扮演着关键角色。

### Transformer 与 Self-Attention 的关系

1. **Self-Attention**:
   - **定义**：Self-Attention，也称为自注意力机制，是一种注意力机制，它允许输入序列的每个元素都与序列中的其他所有元素进行交互，以计算序列的表示。它关注的是同一个序列内部的元素之间的关系。
   - **作用**：自注意力机制能够帮助捕捉序列中各元素之间的长距离依赖关系。

2. **Transformer**:
   - **定义**：Transformer 是一个模型架构，它使用了自注意力机制（特别是多头自注意力）作为其核心组成部分。
   - **关系**：在Transformer中，自注意力机制用于编码器和解码器的每个层，帮助模型理解输入数据（如文本）中不同部分之间的复杂关系。

### QKV 的含义和作用

在自注意力机制中，QKV 分别代表 Query（查询）、Key（键）和 Value（值）。这三个组件是自注意力计算的核心。

1. **Query（查询）**:
   - **含义**：Query 是当前位置的表示，用于与其他位置的 Key 进行匹配。
   - **作用**：Query 表示要寻找相关信息的请求。

2. **Key（键）**:
   - **含义**：Key 代表序列中每个位置的标识，用于与 Query 进行匹配。
   - **作用**：Key 用于确定每个元素与 Query 的相关程度。

3. **Value（值）**:
   - **含义**：Value 是序列中每个位置的内容表示。
   - **作用**：一旦确定了 Query 与各个 Key 的匹配程度，将使用对应的 Value 来计算最终的输出表示。

### 自注意力机制的计算流程

1. **计算注意力得分**：首先计算 Query 与每个 Key 的匹配程度，通常通过计算它们的点积并应用一个缩放因子。

2. **应用 Softmax**：对这些得分应用 Softmax 函数，将它们转换为概率分布，这些概率表示不同 Value 对当前位置的重要性。

3. **计算加权和**：最后，根据这些概率，计算 Value 的加权和，得到每个位置的新表示。

在Transformer模型中，这个过程在每个编码器和解码器层中都会发生，使模型能够有效地处理序列数据中的复杂关系。通过这种方式，Transformer 利用自注意力机制学习输入数据的内部结构，从而实现高效且准确的数据处理。

![](../../youdaonote-images/Pasted%20image%2020231216170929.png)

![](../../youdaonote-images/Pasted%20image%2020231216171110.png)

![](../../youdaonote-images/Pasted%20image%2020231216170403.png)

![](../../youdaonote-images/Pasted%20image%2020231216170425.png)


## 走向不同：GPT与BERT的选择

![](../../youdaonote-images/Pasted%20image%2020231216171539.png)

BERT（Bidirectional Encoder Representations from Transformers）是一种基于Transformer架构的预训练语言表示模型。由Google在2018年提出，它在自然语言处理（NLP）领域引起了革命性的变化。BERT的关键创新在于其双向的训练方式，它可以更全面地理解语言上下文。

### BERT的核心特点

1. **双向训练**:
    
    - BERT使用双向Transformer编码器。与之前的模型（如OpenAI的GPT）不同，BERT同时考虑了文本左侧和右侧的上下文信息，从而提供更全面的语言理解。
2. **基于Transformer**:
    
    - BERT基于Transformer模型，特别是其自注意力机制的编码器部分。这使得BERT在处理文本时能够有效地捕捉长距离依赖。
3. **预训练和微调**:
    
    - BERT采用了预训练加微调的训练方式。首先在大规模文本数据集上进行预训练，学习通用的语言表示，然后在特定任务上进行微调。

### BERT的预训练任务

BERT通过两种预训练任务学习语言表示：

1. **掩码语言模型（Masked Language Model, MLM）**:
    
    - 在这个任务中，BERT随机遮盖（mask）输入文本中的某些单词，然后预测这些遮盖单词的原始值。这种方法迫使模型根据上下文理解单词的意义。
2. **下一句预测（Next Sentence Prediction, NSP）**:
    
    - 在这个任务中，BERT试图预测给定句子对中的第二句是否是第一句的下一句。这有助于模型学习句子间的关系，对问答和自然语言推理等任务特别有用。

### BERT的自编码

1. **定义**:
    
    - 自编码是一种模型训练方法，其中模型被训练来预测输入数据中被随机遮盖（或隐藏）的部分。这种方法强迫模型学习理解和表示整个输入数据的上下文。
2. **BERT中的应用**:
    
    - 在BERT中，自编码通过掩码语言模型（Masked Language Model, MLM）来实现。在预训练阶段，BERT随机遮盖输入序列中的一些词汇（例如，将它们替换为一个特殊的[MASK]标记），然后模型被训练来预测这些遮盖词汇的原始值。
3. **特点**:
    
    - 这种方法使得BERT能够有效地学习到双向的上下文信息，因为它必须同时考虑被遮盖词的左侧和右侧上下文。

### GPT的自回归

1. **定义**:
    
    - 自回归是一种模型训练方法，其中模型被训练来预测序列中的下一个词或字符。这种方法基于到目前为止已经观察到的序列，生成或预测下一个输出。
2. **GPT中的应用**:
    
    - 在GPT（Generative Pre-trained Transformer）中，自回归方法用于语言模型训练。GPT接收到一个词序列后，预测序列中的下一个词。这种训练方式让模型学习到如何基于之前的词生成文本。
3. **特点**:
    
    - GPT的这种方法强调单向的上下文（即只考虑每个词左侧的词），这使得它在生成连贯和流畅的文本方面表现突出。

![](../../youdaonote-images/Pasted%20image%2020231216194905.png)

![](../../youdaonote-images/Pasted%20image%2020231216195007.png)
# GPT 模型家族：从始至今

## 从GPT-1到GPT-3.5：一路的风云变幻

### NLP 语言模型技术发展一览

![](../../youdaonote-images/Pasted%20image%2020231217211725.png)

### 预训练语言模型 (Pre-trained language models)

![](../../youdaonote-images/Pasted%20image%2020231217212329.png)

### 预训练语言模型的三种网络架构（2018-2020）

**编码器**：编码器主要用于处理和理解输入信息。这些模型可以获得双向的上下文，即可以同时考虑一个词的前面和后面的信息。由于编码器可以考虑到未来的信息，它们非常适合用于需要理解整个句子的任务，如文本分类、命名实体识别等。预训练编码器需要使其能够构建强大的表示，这通常通过预测某个被遮蔽的单词、预测下一个句子或者其它的预训练任务来实现。BERT就是一种典型的预训练编码器。

**解码器**：解码器主要用于生成输出信息。它们是语言模型的基础，用于预测下一个单词。解码器只能考虑到过去的词，而不能考虑到未来的词，这使得它们非常适合于生成任务，如文本生成、对话系统等。GPT就是一种典型的预训练解码器。

**编码器-解码器**：编码器-解码器结构结合了编码器和解码器的优点。编码器首先处理输入信息，然后解码器生成输出信息。这种结构可以考虑到全局的上下文信息，因此非常适合于需要理解输入信息并生成相应的输出的任务，如机器翻译、文本摘要等。如何预训练编码器-解码器模型是一个开放的问题，因为需要考虑到如何有效地使用编码器和解码器的特点。T5和BART都是典型的预训练编码器-解码器模型。

![](../../youdaonote-images/Pasted%20image%2020231217212552.png)

GPT-1：通过以下方式提高语言理解能力生成式预训练，OpenAI

![](../../youdaonote-images/Pasted%20image%2020231217212808.png)

### NLP基准测试介绍

- MNLI-m (Multi-Genre Natural Language Inference, matched)：这是一个自然语言推理任务，其中包括了五个不同类型（类型指的是来源，例如口语、小说等）的文本，并且这些文本在训练和测试集上都是匹配的。任务的目标是根据一个给出的前提判断一个假设是蕴含、矛盾，还是无关。
- MNLI-mm (Multi-Genre Natural Language Inference, mismatched)：这也是一个自然语言推理任务，但与MNLI-m不同的是，训练集和测试集的文本类型是不匹配的。这需要模型具有更好的泛化能力。
- SNLI (Stanford Natural Language Inference)：这是一个由斯坦福大学创建的自然语言推理任务，包含了大约55万个人类注释的英文句子对。任务的目标同样是根据一个给出的前提判断一个假设是蕴含、矛盾，还是无关。
- SciTail：这是一个开放的自然语言推理任务，所有的问题和答案都来自科学领域的教材。任务的目标是根据一个给出的前提判断一个假设是蕴含还是矛盾。
- QNLI (Question Natural Language Inference)：这是一个基于问答的自然语言推理任务，数据来源于SQuAD数据集。任务的目标是根据给出的上下文判断一个假设（问题）是否被蕴含。
- RTE (Recognizing Textual Entailment)：这是一个文本蕴含识别任务，数据来源于多个版本的PASCAL RTE挑战赛。任务的目标是根据一个给出的前提判断一个假设是蕴含还是矛盾。

![](../../youdaonote-images/Pasted%20image%2020231217213828.png)

### 三个概念
**In-Context Learning**：在上下文中学习指的是大型语言模型如GPT-3的一种能力，即在给定的上下文中使用新的输入来改善模型的输出。这种学习方式并不涉及到梯度更新或微调模型的参数，而是通过提供一些具有特定格式或结构的示例输入，使模型能够在生成输出时利用这些信息。例如，如果你在对话中包含一些英法翻译的例子，然后问模型一个新的翻译问题，模型可能会根据你提供的上下文示例生成正确的翻译。

**Few-Shot Learning**：少样本学习是指用极少量的标注样本来训练机器学习模型的技术。在GPT-3的案例中，少样本学习的实现方式是向模型提供少量的输入-输出对示例，这些示例作为对话的一部分，描述了模型应该执行的任务。然后，模型会生成一个输出，该输出是对与示例类似的新输入的响应。例如，你可以给模型提供几个英法翻译的例子，然后给出一个新的英文单词让模型翻译，模型会尝试产生一个正确的翻译。

**Prompt Engineering**：提示工程是指设计和优化模型的输入提示以改善模型的输出。在大型语言模型中，如何提问或构造输入的方式可能对模型的输出有重大影响。因此，选择正确的提示对于获取有用的输出至关重要。例如，为了让GPT-3生成一个诗歌，你可能需要提供一个详细的、引导性的提示，如“写一首关于春天的十四行诗” ，而不仅仅是“写诗” 。

### OpenAI的模型迭代：预训练与微调的共舞

在 GPT 模型的演进过程中，OpenAI 采用了一系列的训练策略，这包括基础的大规模预训练，也包括后续的指令微调等方法。这两种策略在模型的训练过程中起到了不同的作用。

- **预训练(Pre-Trained)**：大规模预训练是为了使模型获取丰富的语言知识和理解能力。在预训练过程中，模型通过大量的无标签数据来学习语言的基础知识，这一过程主要是依赖无监督学习的。
- **指令微调(Instruction-Tuning)**：在预训练模型的基础上，通过针对特定任务的标注数据进行微调，能够使模型在特定任务上的表现得到提升。同时，通过对微调数据的精心设计和选择，还能够引导模型按照人类的预期来执行任务。这一过程主要依赖有监督学习。

在这个过程中，预训练和微调是相辅相成的。预训练为模型提供了丰富的语言知识，而微调则利用这些知识来解决特定的任务。然而，微调的数据量通常比预训练的数据量要少得多，因此微调的主要作用并不是为模型注入新的知识，而是**激发和引导模型利用已有的知识来完成特定任务**

OpenAI还注意到，模型在进行微调时可能会出现一些问题，例如数据稀疏性、灾难遗忘、资源浪费和通用性差等。为了解决这些问题，OpenAI提出了一种新的训练策略，即提示学习。通过设计提示信息，可以激发预训练大模型的能力，从而提高模型在具体任务上的表现。

### 初代 GPT-3.5 : code-davinci-002

初代GPT-3.5系列（以下简称新模型）相比 GPT-3 系列模型，具有以下优点：

- 人类指令响应 (Responding to Human Instructions)：新模型能针对特定指令生成更恰当的回应，而非回复训练集中频繁出现的无关句子。

- 任务泛化能力 (Task Generalization)：当新模型接收大量指令调整后，能自动适应并有效回答未见过的新指令，这在应对用户不断变化的问题上至关重要。

- 代码理解与生成 (Code Understanding and Generation)：经过代码训练的新模型能理解并生成代码，强化了编程相关应用的能力。

- 复杂推理的思维链 (Chain of Thought for Complex Reasoning)：新模型已提高思维链推理能力，使其能处理需要多步推理的问题，这可能是突破模型缩放法则(scaling laws)限制，实现真正的突现性能力的关键。

### ChatGPT 的三段训练法

![](../../youdaonote-images/Pasted%20image%2020231217215250.png)
## GPT-4：一个新的开始

# 提示学习（Prompt Learning）

## 思维链（Chain-of-Thought, CoT）：开山之作

## 自洽性（Self-Consistency）：多路径推理

## 思维树（Tree-of-Thoughts, ToT）：续写佳话