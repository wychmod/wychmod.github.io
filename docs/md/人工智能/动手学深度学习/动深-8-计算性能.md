# 动深-8-计算性能
[toc]
## 8.1 命令式和符号式混合编程
![image.png](https://note.youdao.com/yws/res/a/WEBRESOURCE93cfc26d56e7335cdb1762e48ce5b68a)

https://trickygo.github.io/Dive-into-DL-TensorFlow2.0/#/chapter08_computational-performance/8.1_hybridize

## 8.2 异步计算
Tensorflow使用异步计算来提升计算性能。理解它的工作原理既有助于开发更高效的程序，又有助于在内存资源有限的情况下主动降低计算性能从而减小内存开销。我们先导入本节中实验需要的包或模块。
```
import tensorflow as tf
import tensorflow.keras as keras
import os
import subprocess
import time
```

### 8.2.1 Tensorflow 中的异步计算
广义上讲，Tensorflow包括用户直接用来交互的前端和系统用来执行计算的后端。例如，用户可以使用不同的前端语言编写Tensorflow程序，如Python、C++和Javascript。无论使用何种前端编程语言，Tensorflow程序的执行主要都发生在C++实现的后端。换句话说，用户写好的前端Tensorflow程序会传给后端执行计算。后端有自己的线程在队列中不断收集任务并执行它们。

此设计的一个好处是，这里的Python前端线程不需要做实际计算。因此，无论Python的性能如何，它对整个程序性能的影响很小。只要C++后端足够高效，那么不管前端编程语言性能如何，Tensorflow都可以提供一致的高性能。

### 8.2.2 用同步函数让前端等待计算结果

### 8.2.3 使用异步计算提升计算性能
在下面的例子中，我们用for循环不断对变量y赋值。当在for循环内执行y = x + 1时，每次赋值不使用异步计算；当在for循环外使用tf.function装饰时，则使用异步计算。

```
with Benchmark('synchronous.'):
  for _ in range(1000):
    y = x + 1

@tf.function
def loop():
  for _ in range(1000):
    y = x + 1
  return y

with Benchmark('asynchronous.'):
  y = loop()

    synchronous. time: 3.5589 sec
    asynchronous. time: 1.0457 sec

```
我们观察到，使用异步计算能提升一定的计算性能。为了解释这一现象，让我们对Python前端线程和C++后端线程的交互稍作简化。在每一次循环中，前端和后端的交互大约可以分为3个阶段：

1. 前端令后端将计算任务y = x + 1放进队列；
2. 后端从队列中获取计算任务并执行真正的计算；
3. 后端将计算结果返回给前端。

我们将这3个阶段的耗时分别设为 t1,t2,t3 。如果不使用异步计算，执行1000次计算的总耗时大约为 1000(t1+t2+t3) ；如果使用异步计算，由于每次循环中前端都无须等待后端返回计算结果，执行1000次计算的总耗时可以降为 t1+1000t2+t3 （假设 1000t2>999t1 ）。

### 8.2.4 异步计算对内存的影响

### 8.2.5 小结
- Tensorflow包括用户直接用来交互的前端和系统用来执行计算的后端。
- Tensorflow能够通过生成更大规模的计算图，使后端异步计算时间更长，更少被打断，从而提升计算性能。
- 建议使用每个小批量训练或预测时以batch为单位生成计算图，从而避免在短时间内将过多计算任务丢给后端

## 8.3 自动并行计算
Tensorflow后端会自动构建计算图。通过计算图，系统可以知道所有计算的依赖关系，并可以选择将没有依赖关系的多个任务并行执行来获得计算性能的提升。例如“异步计算”一节的第一个例子里依次执行了a = tf.ones((1, 2))和b = tf.ones((1, 2))。这两步计算之间并没有依赖关系，因此系统可以选择并行执行它们。

通常，一个运算符会用到所有CPU或单块GPU上全部的计算资源。例如，dot运算符会用到所有CPU（即使是一台机器上有多个CPU处理器）或单块GPU上所有的线程。如果每个运算符的计算量足够大，只在CPU上或者单块GPU上并行运行多个运算符时，每个运算符的运行只分到CPU或单块GPU上部分计算资源。即使这些计算可以并行，最终计算性能的提升可能也并不明显。本节中探讨的自动并行计算主要关注同时使用CPU和GPU的并行计算，以及计算和通信的并行。

### 8.3.1 CPU和GPU的并行计算
### 8.3.2 计算和通信的并行计算
