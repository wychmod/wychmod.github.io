内存是软件系统必不可少的物理资源，精湛的内存管理技术是确保内存使用效率的关键，也是进阶高级研发的必备技巧。为提高内存分配效率，_Python_ 内部做了很多殚心竭虑的优化，从中我们可以获得一些启发。

开始研究 _Python_ 内存池之前，我们先大致了解下 _Python_ 内存管理层次：

![](../../youdaonote-images/Pasted%20image%2020221218145801.png)

众所周知，计算机硬件资源由操作系统负责管理，内存资源也不例外。应用程序通过 **系统调用** 向操作系统申请内存，而 _C_ 库函数则进一步将系统调用封装成通用的 **内存分配器** ，并提供了 _malloc_ 系列函数。

_C_ 库函数实现的通用目的内存管理器是一个重要的分水岭，即内存管理层次中的 **第 0 层** 。此层之上是应用程序自己的内存管理，此层之下则是隐藏在冰山下方的操作系统部分。

操作系统内部是一个基于页表的虚拟内存管理器 (**第 - 1 层**)，以 **页** ( _page_ ) 为单位管理内存，_CPU_ **内存管理单元** ( _MMU_ ) 在这个过程中发挥重要作用。虚拟内存管理器下方则是底层存储设备 ( **第 - 2 层**)，直接管理物理内存以及磁盘等二级存储设备。

绿色部分则是 _Python_ 自己的内存管理，分为 _3_ 层：

-   第 _1_ 层，是一个内存分配器，接管一切内存分配，内部是本文的主角 —— **内存池** ；
-   第 _2_ 层，在第 1 层提供的统一 _PyMem_XXXX_ 接口基础上，实现统一的对象内存分配 ( _object.tp_alloc_ )；
-   第 _3_ 层，为特定对象服务，例如前面章节介绍的 _float_ 空闲对象缓存池；

那么，_Python_ 为什么不直接使用 _malloc_ 系列函数，而是自己折腾一遍呢？原因主要是以下几点：

-   引入内存池，可化解对象频繁创建销毁带来的内存分配压力；
-   最大程度避免内存碎片化，提升内存利用效率；
-   _malloc_ 有很多实现版本，不同实现性能千差万别；

## 内存碎片的挑战

**内存碎片化** 是困扰经典内存分配器的一大难题，碎片化导致的结果也是惨重的。这是一个典型的内存碎片化例子：

![](../../youdaonote-images/Pasted%20image%2020221218150109.png)

虽然还有 _1900K_ 的空闲内存，但都分散在一系列不连续的碎片上，甚至无法成功分配出 _1000K_ 。

那么，如何避免内存碎片化呢？想要解决问题，必先分析导致问题的根源。

我们知道，应用程序请求内存块尺寸是不确定的，有大有小；释放内存的时机也是不确定的，有先有后。经典内存分配器将不同尺寸内存块混合管理，按照先来后到的顺序分配：

![](../../youdaonote-images/Pasted%20image%2020221218150329.png)

当大块内存回收后，可以被分为更小的块，然后分配出去：

![](../../youdaonote-images/Pasted%20image%2020221218150351.png)

而先分配的内存块未必先释放，慢慢地空洞就出现了：

![](../../youdaonote-images/Pasted%20image%2020221218151732.png)

随着时间的推移，碎片化会越来越严重，最终变得支离破碎：

![](../../youdaonote-images/Pasted%20image%2020221218151741.png)

由此可见，将不同尺寸内存块混合管理，将大块内存切分后再次分配的做法是罪魁祸首。

## 按尺寸分类管理

揪出内存碎片根源后，解决方案也就浮出水面了 —— 根据内存块尺寸，将内存空间划分成不同区域，独立管理。举个最简单的例子：