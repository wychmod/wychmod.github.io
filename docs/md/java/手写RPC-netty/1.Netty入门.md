# 上网必备因素

1. 网卡 
2. IP地址 （局域网IP，公网IP 【运营商分配】）
3. 路由器
4. 交换机
5. 网线 （数据发送出去了）
6. 如果数据在发送的过程中，有时间，有流动性，水流的时候 突然放上指头，水就会断一下
7. 接收方，接收数据的时候，怎么判断数据接收完成
8. socket套接字

# Netty入门

> Netty是一款基于NIO（Nonblocking I/O，非阻塞IO）开发的网络通信框架
## 1. 理解IO模型

> 以两个应用程序通讯为例：应用A向应用B发送一条消息

![](../../youdaonote-images/Pasted%20image%2020241118154242.png)

步骤：**

1. 应用A把消息发送到 TCP发送缓冲区
2. TCP发送缓冲区再把消息发送出去，经过网络传递后，消息会发送到B服务器的TCP接收缓冲区
3. B再从TCP接收缓冲区去读取属于自己的数据

## 1.1 阻塞IO

> 在上图中，应用B从TCP接收缓冲区接收数据的时候，会出现以下情况：
>
> 1. 消息的发送不是一个持续状态，也就是说TCP接收缓冲区中可能没有B需要的消息
> 2. B去TCP接收缓冲区拿取消息的时候，拿不到对应的消息

**这时候TCP接收缓冲区产生了一个问题？**

1. 告诉B，现在无消息，你该干啥干啥去
2. 告诉B，现在无消息，你等一会，消息一会就来

> 思考A发送消息到TCP发送缓冲区的过程，同样会出现以下情况：
>
> 1. TCP发送缓冲区满了，也就是说A发送的消息TCP发送缓冲区接收不了
> 2. A无法成功的将消息发送到TCP发送缓冲区

**这时候TCP发送缓冲区产生了一个问题？**

1. 告诉A，现在缓冲区满了，你该干啥干啥去
2. 告诉A，现在缓冲区满了，你等一会，有空间的时候，你在拷贝数据到缓冲区



> 那么什么是阻塞IO？

以应用B为例，阻塞IO就是，当B发起读取数据的请求，内核数据没有准备好之前，B一直处于等待状态，直到内核将数据准备好，交给B为止。

**术语描述**：在应用调用recvfrom读取数据时，其系统调用直到数据包到达且被复制到应用缓冲区中或者发送错误时才返回，在此期间一直会等待，进程从调用到返回这段时间内都是被阻塞的，称为阻塞IO。

`recvfrom`用来接收远程主机经指定的socket 传来的数据, 并把数据存到由参数buf 指向的内存空间。



> 小知识：套接字是网络编程中的一种通信机制，是支持TCP/IP的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。



**流程：**

1. 应用进程向内核发起recvfrom读取数据
2. 准备数据报（应用进程阻塞）
3. 将数据从内核复制到应用空间
4. 复制完成后，返回成功提示

![](../../youdaonote-images/Pasted%20image%2020241118154324.png)
## 1.2 非阻塞IO

> 很明显，非阻塞IO就是，内核数据没有准备好之前，会直接通知B未准备好，让B不要等待了
>
> B 问 准备好了吗？内核 没准备好 过了一会 B又问：准备好了吗？

**术语**：非阻塞IO是在应用调用recvfrom读取数据时，如果该缓冲区没有数据的话，就会直接返回一个EWOULDBLOCK错误，不会让应用一直等待中。在没有数据的时候会即刻返回错误标识，那也意味着如果应用要读取数据就需要不断的调用recvfrom请求，直到读取到它数据要的数据为止。

**流程：**

1. 应用进程向内核发起recvfrom读取数据
2. 没有数据报准备好，即刻返回EWOULDBLOCK错误码
3. 应用进程向内核发起recvfrom读取数据
4. 已有数据包准备好就进行一下 步骤，否则还是返回错误码
5. 将数据从内核拷贝到用户空间
6. 完成后，返回成功提示

![](../../youdaonote-images/image-20211010200211732.png)

## 1.3 IO复用模型

> 还是B从TCP缓冲区中读取数据，如果在并发的环境下，可能会N个人向应用B发送消息，这种情况下我们的应用就必须创建多个线程去读取数据，每个线程都会自己调用recvfrom 去读取数据。那么此时情况可能如下图：

![](../../youdaonote-images/image-20211010204520156.png)

这时候，我们假设并发的规模扩大到百万，也就是说B需要创建上百万的线程去读取数据，由于B不知道数据到底什么时候有，所以不断的向内核发送recvfrom请求来读取数据**


> 这时候，大家应该发现问题了，这么多线程一直不停的发recvfrom请求，系统能不能扛得住是一个问题，即使能抗的住，很明显，资源浪费太严重了。
>
> 线程是我们操作系统的宝贵资源，如果线程都浪费在这了，那还有线程可以去做别的事情吗？

**有问题，就要解决**

> 有人提出了这样的思路，可以有一个或者多个线程监控多个网络请求（**fd文件描述符**，**linux系统把所有网络请求以一个fd来标识**），这样就可以只需要一个或几个线程就可以完成数据状态询问的操作，当有数据准备就绪之后再分配对应的线程去读取数据，这么做就可以节省出大量的线程资源出来，这个就是IO复用模型的思路


![](../../youdaonote-images/image-20211011195026941.png)


**术语描述：进程通过将一个或多个fd传递给select，阻塞在select操作上，select帮我们侦测多个fd是否准备就绪，当有fd准备就绪时，select返回数据可读状态，应用程序再调用recvfrom读取数据

> 复用IO的基本思路就是通过select或poll、epoll 来监控多fd ，来达到不必为每个fd创建一个对应的监控线程，从而减少线程资源创建的目的。

## 1.4 信号驱动IO模型

> 上述的IO复用模型，我们从图上发现了一个问题，select是采用轮询的方式来监控多个fd，这种无脑的轮询显得没有必要，极大的浪费性能，大部分的轮询都是无效的。
>
> 这时候就提出了一个新的思想，能不能不要我总是去问你是否数据准备就绪，能不能我发出请求后等你数据准备好了就通知我，这就衍生了信号驱动IO模型



**术语描述：首先开启套接口信号驱动IO功能，并通过系统调用sigaction执行一个信号处理函数，此时请求即刻返回，当数据准备就绪时，就生成对应进程的SIGIO信号，通过信号回调通知应用线程调用recvfrom来读取数据。



>  IO复用模型里面的select虽然可以监控多个fd了，但select其实现的本质上还是通过不断的轮询fd来监控数据状态， 因为大部分轮询请求其实都是无效的，所以信号驱动IO意在通过这种建立信号关联的方式，实现了发出请求后只需要等待数据就绪的通知即可，这样就可以避免大量无效的数据状态轮询操作。

![](../../youdaonote-images/image-20211011204533693.png)

>  IO复用模型里面的select虽然可以监控多个fd了，但select其实现的本质上还是通过不断的轮询fd来监控数据状态， 因为大部分轮询请求其实都是无效的，所以信号驱动IO意在通过这种建立信号关联的方式，实现了发出请求后只需要等待数据就绪的通知即可，这样就可以避免大量无效的数据状态轮询操作。

## 1.5 异步IO

> 不管是IO复用还是信号驱动，我们要读取一个数据总是要发起两阶段的请求，第一次发送select请求，询问数据状态是否准备好，第二次发送recevform请求读取数据。

**很明显，我们的需求是读数据，为什么要询问状态呢？**

能不能这么做？

**应用只需要向内核发送一个read 请求,告诉内核它要读取数据后即刻返回；内核收到请求后会建立一个信号联系，当数据准备就绪，内核会主动把数据从内核复制到用户空间，等所有操作都完成之后，内核会发起一个通知告诉应用**

> 上述的思想就是异步IO模型

![](../../youdaonote-images/image-20211011205715492.png)

**术语描述：** 应用告知内核启动某个操作，并让内核在整个操作完成之后，通知应用，这种模型与信号驱动模型的主要区别在于，信号驱动IO只是由内核通知我们合适可以开始下一个IO操作，而异步IO模型是由内核通知我们操作什么时候完成。

> 异步IO的优化思路是解决了应用程序需要先后发送询问请求、发送接收数据请求两个阶段的模式，在异步IO的模式下，只需要向内核发送一次请求就可以完成状态询问和数拷贝的所有操作。

# 2. BIO,NIO,AIO

## 2.1 BIO

> BIO 全称Block-IO 是一种**同步且阻塞**的通信模式

阻塞就是发起读取数据请求的时，当数据还没准备就绪的时候，这时请求是即刻返回，还是在这里等待数据的就绪，如果需要等待的话就是阻塞，反之如果即刻返回就是非阻塞。

在IO模型里面如果请求方从发起请求到数据最后完成的这一段过程中都需要自己参与，那么这种我们称为同步请求；反之，如果应用发送完指令后就不再参与过程了，只需要等待最终完成结果的通知，那么这就属于异步。

![](../../youdaonote-images/image-20211017174533658.png)

如上图，是典型的BIO模型，每当有一个连接到来，经过协调器的处理，就开启一个对应的线程进行接管。如果连接有1000条，那就需要1000个线程。线程资源是非常昂贵的，除了占用大量的内存，还会占用非常多的CPU调度时间，所以BIO在连接非常多的情况下，效率会变得非常低。

下面的代码是使用`ServerSocket`实现的一个简单socket服务器，监听在8888端口：

